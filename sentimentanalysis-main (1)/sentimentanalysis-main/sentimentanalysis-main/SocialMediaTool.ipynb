{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53f502f3-f0cb-4a39-98b7-5244eedb44ae",
   "metadata": {},
   "source": [
    "# Social media analysis\n",
    "We are going to use a modified example taken from Wintjen M (2020) \"Practical Analysis Using Jupyter Notebook\" pp 264-\n",
    "\n",
    "##  Set-up\n",
    "> 1. install a non-standard python module nltk - natural language toolkit to add in functions we need\n",
    "> 2. Add is pandas as pd and numpy as np\n",
    "> 3. inline version matplotlib #look it up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43d5db7e",
   "metadata": {},
   "source": [
    "VADER (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in social media. It is designed to be sensitive to both positive and negative sentiment, as well as the intensity of the sentiment.\n",
    "\n",
    "VADER uses a combination of a dictionary of lexical features and a set of rules to assign a sentiment score to a piece of text. The dictionary contains words and phrases that are commonly associated with positive or negative sentiment, as well as words and phrases that indicate the intensity of the sentiment. The rules take into account the context in which the words and phrases are used, as well as other factors such as capitalization and punctuation.\n",
    "\n",
    "Using VADER, it is possible to accurately identify and quantify the sentiment of text data, such as social media posts or customer reviews. This can be useful for a variety of applications, such as analyzing customer feedback or social media posts to understand the overall sentiment about a product or service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "879ea9a9-04bb-45a7-b65e-f236326c90d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (3.8)\n",
      "Requirement already satisfied: click in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\azaz\\appdata\\roaming\\python\\python311\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk\n",
    "\n",
    "#! pip install git+https://github.com/tweepy/tweepy.git\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0f9808fd",
   "metadata": {},
   "source": [
    "The first line of code installs the nltk library using the pip package manager. This is necessary if the nltk library is not already installed on your system.\n",
    "\n",
    "The second line of code is commented out, so it will not be executed. This line of code would install the tweepy library using pip and a Git URL.\n",
    "\n",
    "The next three lines of code import the nltk, pandas, and numpy libraries into the current Python script or notebook. The import statements make the functions and objects defined in these libraries available to be used in the script or notebook.\n",
    "\n",
    "The final line of code, %matplotlib inline, is a magic command that is used to configure Matplotlib, a plotting library, to display plots within the notebook. This allows you to see the plots that are generated by Matplotlib without having to save them to a file and view them separately."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "015b2351",
   "metadata": {},
   "source": [
    "! pip is a command that is used to run the pip package manager from the command line. pip is a tool for installing and managing Python packages, which are collections of modules that provide additional functionality to Python. The ! symbol is used to indicate that the following command should be run in the command line, rather than in the Python interpreter."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e8c2ac5",
   "metadata": {},
   "source": [
    "% is a special symbol in IPython (an interactive shell for Python) that is used to indicate a magic command. Magic commands are special commands that are not part of the Python language, but provide additional functionality within the IPython environment. For example, the %matplotlib magic command is used to configure the Matplotlib plotting library to display plots within the IPython environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f12b43d-9cbe-4373-9707-daa7ceecace8",
   "metadata": {},
   "source": [
    "## Next stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c41fa69-2465-44dc-9420-1da748dc65e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Azaz\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "anlysr=SentimentIntensityAnalyzer()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "515ae264",
   "metadata": {},
   "source": [
    "The first line of code, nltk.download('vader_lexicon'), downloads the vader_lexicon data package from the Natural Language Toolkit (nltk) library. The vader_lexicon is a lexicon (a list of words and their associated sentiment scores) that is used by the SentimentIntensityAnalyzer in the nltk library to perform sentiment analysis.\n",
    "\n",
    "The next two lines of code import the SentimentIntensityAnalyzer class from the nltk.sentiment.vader module and create an instance of the SentimentIntensityAnalyzer class, which is stored in a variable called anlysr.\n",
    "\n",
    "The SentimentIntensityAnalyzer class provides methods for calculating the sentiment intensity (i.e., the positivity, negativity, or neutrality) of a piece of text. Once the anlysr object is created, you can use its methods to perform sentiment analysis on text data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544f32b-4c9c-47d9-bdc6-56c44132b472",
   "metadata": {},
   "source": [
    "## next stage\n",
    "> 1. load in the tweet data\n",
    "> 2. As a quick check see a few examples top of the list\n",
    "> 3. Set up variables for out four categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01468155-02b0-4a2c-a25c-81025fd80083",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_data=pd.read_csv('tweet_activity.csv')\n",
    "the_data.head()\n",
    "score_compound=[]\n",
    "score_positive=[]\n",
    "score_negative=[]\n",
    "score_neutral=[]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0ce7633a",
   "metadata": {},
   "source": [
    "The first line of code, the_data=pd.read_csv('tweet_activity.csv'), uses the read_csv function from the pandas library to read in data from a CSV file called tweet_activity.csv and store it in a Pandas dataframe called the_data.\n",
    "\n",
    "The second line of code, the_data.head(), displays the first few rows of the dataframe using the head method. This can be useful for getting a feel for the structure and content of the data.\n",
    "\n",
    "The next four lines of code create four empty lists called score_compound, score_positive, score_negative, and score_neutral. These lists will be used to store the results of sentiment analysis that is performed on the data in the the_data dataframe. The score_compound list will store the compound sentiment scores, which are normalized scores that range from -1 (most negative) to 1 (most positive). The score_positive, score_negative, and score_neutral lists will store the positive, negative, and neutral sentiment scores, respectively. These scores are not normalized and represent the raw positivity, negativity, or neutrality of the text."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d916bf44",
   "metadata": {},
   "source": [
    "the_data.head() is a method of a Pandas dataframe that displays the first few rows of the dataframe. By default, it displays the first 5 rows, but you can specify a different number of rows to display by passing an integer as an argument to the head method. For example, the_data.head(10) would display the first 10 rows of the the_data dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2f297d-b84d-454c-b27a-aa0f5e4549ad",
   "metadata": {},
   "source": [
    "## next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13e62c8d-0e82-4ebf-85a3-7ed19e9a8756",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "while (i<len(the_data)):\n",
    "    my_anlysr=anlysr.polarity_scores(the_data.iloc[i]['Tweet text'])\n",
    "    score_compound.append(my_anlysr['compound'])\n",
    "    score_positive.append(my_anlysr['pos'])\n",
    "    score_negative.append(my_anlysr['neg'])\n",
    "    score_neutral.append(my_anlysr['neu'])\n",
    "    i=i+1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "85249ac9",
   "metadata": {},
   "source": [
    "This code block appears to be iterating through the rows of the the_data dataframe and performing sentiment analysis on the 'Tweet text' column of each row.\n",
    "\n",
    "The i variable is initialized to 0 and is used as an index to keep track of the current row being processed. The while loop continues to run as long as i is less than the length of the dataframe (i.e., the number of rows in the dataframe).\n",
    "\n",
    "Inside the loop, the polarity_scores method of the anlysr object is called on the 'Tweet text' column of the current row. This method returns a dictionary of sentiment scores for the text, including the compound score (normalized from -1 to 1), as well as the positive, negative, and neutral scores.\n",
    "\n",
    "The compound, positive, negative, and neutral scores are then appended to the appropriate lists using the append method. Finally, the i variable is incremented by 1 to move to the next row in the dataframe.\n",
    "\n",
    "After the loop completes, the score_compound, score_positive, score_negative, and score_neutral lists will contain the sentiment scores for each row of the the_data dataframe."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6f97497",
   "metadata": {},
   "source": [
    "iloc is an attribute of Pandas dataframes that allows you to access rows and columns by their integer-based index. It is used to index rows and columns of a dataframe using integers, rather than the labels or names of the rows or columns. For example, df.iloc[0, 0] would select the element at the first row and first column of the df dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f1a5f4-4206-47bd-b9bf-06ce1b4409e7",
   "metadata": {},
   "source": [
    "# Next step\n",
    "> 1. Convert to numpy to make it easier to play with \n",
    "> 2. Add the scores into the Data Frame \n",
    "> 3. Display the first 10 items in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cda3f1-b1b5-4d8b-9b55-faa610ecca15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet text</th>\n",
       "      <th>Compound score</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digging into Big Provenance (with SPADE) https...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Road Ahead for Augmented Reality https://t...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computational Thinking for Professionals https...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What makes university students steer clear of ...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caught on camera: Using AI to combat street cr...</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Tweet text  Compound score  \\\n",
       "0  Digging into Big Provenance (with SPADE) https...          0.0000   \n",
       "1  The Road Ahead for Augmented Reality https://t...          0.0000   \n",
       "2  Computational Thinking for Professionals https...          0.0000   \n",
       "3  What makes university students steer clear of ...          0.3818   \n",
       "4  Caught on camera: Using AI to combat street cr...         -0.7096   \n",
       "\n",
       "   Positive score  Negative score  Neutral score  \n",
       "0           0.000           0.000          1.000  \n",
       "1           0.000           0.000          1.000  \n",
       "2           0.000           0.000          1.000  \n",
       "3           0.191           0.000          0.809  \n",
       "4           0.000           0.371          0.629  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_compound=np.array(score_compound)\n",
    "score_positive=np.array(score_positive)\n",
    "score_negative=np.array(score_negative)\n",
    "score_neutral=np.array(score_neutral)\n",
    "\n",
    "the_data['Compound score']=score_compound\n",
    "the_data['Positive score']=score_positive\n",
    "the_data['Negative score']=score_negative\n",
    "the_data['Neutral score']=score_neutral\n",
    "\n",
    "the_data.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61c416a2",
   "metadata": {},
   "source": [
    "This code block appears to be creating new columns in the the_data dataframe and adding the values from the score_compound, score_positive, score_negative, and score_neutral lists as the values for these new columns.\n",
    "\n",
    "First, the score_compound, score_positive, score_negative, and score_neutral lists are converted to NumPy arrays using the np.array function. This allows them to be easily added as new columns to the dataframe.\n",
    "\n",
    "Next, the 'Compound score', 'Positive score', 'Negative score', and 'Neutral score' columns are added to the the_data dataframe using the [] operator and the = operator to assign the values from the NumPy arrays to these new columns.\n",
    "\n",
    "Finally, the head method is called on the the_data dataframe to display the first few rows of the dataframe, including the new columns that have been added. This can be useful for verifying that the new columns have been added correctly and contain the expected values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fbb3b806",
   "metadata": {},
   "source": [
    "the_data['Compound score']=score_compound is an assignment statement that adds a new column to the the_data dataframe called 'Compound score' and assigns the values from the score_compound list as the values for this new column. \n",
    "\n",
    "The [] operator is used to specify the name of the new column, and the = operator is used to assign the values from the score_compound list to this new column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2f5d7c3-93d9-41d6-9579-f471cadd3322",
   "metadata": {},
   "source": [
    "## Next Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23dee6b4-4989-4664-9be7-65cd97286703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet text</th>\n",
       "      <th>Compound score</th>\n",
       "      <th>Positive score</th>\n",
       "      <th>Negative score</th>\n",
       "      <th>Neutral score</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Digging into Big Provenance (with SPADE) https...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Road Ahead for Augmented Reality https://t...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Computational Thinking for Professionals https...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What makes university students steer clear of ...</td>\n",
       "      <td>0.3818</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.809</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caught on camera: Using AI to combat street cr...</td>\n",
       "      <td>-0.7096</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.371</td>\n",
       "      <td>0.629</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Avoid a privacy nightmare with 'Lean Privacy R...</td>\n",
       "      <td>-0.2960</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.804</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Algorithms can decide your marks, your work pr...</td>\n",
       "      <td>0.8225</td>\n",
       "      <td>0.314</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.686</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Amazon-sponsored artwork that 'learns' debuts ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@CCCU_games @SocioViz @CanterburyCCUni @christ...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@CCCU_games @SocioViz @CanterburyCCUni @christ...</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.650</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@junk_bots Don’t tempt me 😀 https://t.co/t3gfq...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@CCCU_games @SocioViz @CanterburyCCUni @christ...</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.882</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Artificial intelligence favors white men under...</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.638</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The age of exascale and the future of supercom...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The #CCCUOpenDay over the last week using @soc...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Twitter data for #CCCUOpenDay over the last we...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>#CCCUopenday via NodeXL https://t.co/90TRZqvQp...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>#lthechat via NodeXL https://t.co/Z9H0N0yowt\\n...</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Robots can use their own whirring to echolocat...</td>\n",
       "      <td>-0.5106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.301</td>\n",
       "      <td>0.699</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>What Hot Dogs Can Teach Us About Number Theory...</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.106</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Tweet text  Compound score  \\\n",
       "0   Digging into Big Provenance (with SPADE) https...          0.0000   \n",
       "1   The Road Ahead for Augmented Reality https://t...          0.0000   \n",
       "2   Computational Thinking for Professionals https...          0.0000   \n",
       "3   What makes university students steer clear of ...          0.3818   \n",
       "4   Caught on camera: Using AI to combat street cr...         -0.7096   \n",
       "5   Avoid a privacy nightmare with 'Lean Privacy R...         -0.2960   \n",
       "6   Algorithms can decide your marks, your work pr...          0.8225   \n",
       "7   Amazon-sponsored artwork that 'learns' debuts ...          0.0000   \n",
       "8   @CCCU_games @SocioViz @CanterburyCCUni @christ...          0.0000   \n",
       "9   @CCCU_games @SocioViz @CanterburyCCUni @christ...          0.8625   \n",
       "10  @junk_bots Don’t tempt me 😀 https://t.co/t3gfq...          0.0000   \n",
       "11  @CCCU_games @SocioViz @CanterburyCCUni @christ...          0.7964   \n",
       "12  Artificial intelligence favors white men under...          0.6249   \n",
       "13  The age of exascale and the future of supercom...          0.0000   \n",
       "14  The #CCCUOpenDay over the last week using @soc...          0.0000   \n",
       "15  Twitter data for #CCCUOpenDay over the last we...          0.0000   \n",
       "16  #CCCUopenday via NodeXL https://t.co/90TRZqvQp...          0.2023   \n",
       "17  #lthechat via NodeXL https://t.co/Z9H0N0yowt\\n...          0.2023   \n",
       "18  Robots can use their own whirring to echolocat...         -0.5106   \n",
       "19  What Hot Dogs Can Teach Us About Number Theory...          0.0772   \n",
       "\n",
       "    Positive score  Negative score  Neutral score Prediction  \n",
       "0            0.000           0.000          1.000          0  \n",
       "1            0.000           0.000          1.000          0  \n",
       "2            0.000           0.000          1.000          0  \n",
       "3            0.191           0.000          0.809          +  \n",
       "4            0.000           0.371          0.629          -  \n",
       "5            0.000           0.196          0.804          -  \n",
       "6            0.314           0.000          0.686          +  \n",
       "7            0.000           0.000          1.000          0  \n",
       "8            0.000           0.000          1.000          0  \n",
       "9            0.350           0.000          0.650          +  \n",
       "10           0.000           0.000          1.000          0  \n",
       "11           0.118           0.000          0.882          +  \n",
       "12           0.362           0.000          0.638          +  \n",
       "13           0.000           0.000          1.000          0  \n",
       "14           0.000           0.000          1.000          0  \n",
       "15           0.000           0.000          1.000          0  \n",
       "16           0.083           0.000          0.917          0  \n",
       "17           0.083           0.000          0.917          0  \n",
       "18           0.000           0.301          0.699          -  \n",
       "19           0.106           0.000          0.894          0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loop=0\n",
    "pred_sentiment=[]\n",
    "while (loop<len(the_data)):\n",
    "    if ((the_data.iloc[loop]['Compound score'])>0.3):\n",
    "        pred_sentiment.append('+')\n",
    "    elif ((the_data.iloc[loop]['Compound score']>=0) & (the_data.iloc[loop]['Compound score']<0.3)):\n",
    "        pred_sentiment.append('0')\n",
    "    else:\n",
    "        pred_sentiment.append('-')\n",
    "    loop=loop+1\n",
    "the_data['Prediction']=pred_sentiment\n",
    "the_data.head(20)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4705765-49c6-4b54-bab0-9b4f11d1940d",
   "metadata": {},
   "source": [
    "## next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d05e2cbd-6dbc-4d8c-b5c2-dcae94df4715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot: ylabel='Prediction'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "the_data.groupby('Prediction').size().plot(kind='barh')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61e2bd1a",
   "metadata": {},
   "source": [
    "This code block appears to be creating a new column called 'Prediction' in the the_data dataframe and adding a prediction of the sentiment of each row based on the 'Compound score' column.\n",
    "\n",
    "The loop variable is initialized to 0 and is used as an index to keep track of the current row being processed. The while loop continues to run as long as loop is less than the length of the dataframe (i.e., the number of rows in the dataframe).\n",
    "\n",
    "Inside the loop, an if statement is used to check the value of the 'Compound score' column for the current row. If the value is greater than 0.3, a '+' symbol is appended to the pred_sentiment list, indicating a positive sentiment. If the value is greater than or equal to 0 and less than 0.3, a '0' symbol is appended to the list, indicating a neutral sentiment. Otherwise, a '-' symbol is appended to the list, indicating a negative sentiment.\n",
    "\n",
    "After the loop completes, the pred_sentiment list will contain predictions of the sentiment for each row of the the_data dataframe. This list is then added as a new column called 'Prediction' to the dataframe using the [] operator and the = operator. Finally, the head method is called on the the_data dataframe to display the first 20 rows of the dataframe, including the new 'Prediction' column. This can be useful for verifying that the new column has been added correctly and contains the expected values."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d3b6f791",
   "metadata": {},
   "source": [
    "# Techniques\n",
    "\n",
    "The sentiment analysis techniques used in the above assignment are based on the VADER (Valence Aware Dictionary and sEntiment Reasoner) tool, which is a lexicon-based method for performing sentiment analysis.\n",
    "\n",
    "Following are the techniques in which Sentiment analysis techniques can be used:\n",
    "\n",
    "Analyzing the sentiment of social media posts or other text data:\n",
    "This technique involves using the VADER tool or a similar sentiment analysis method to analyze the sentiment of a large collection of text data, such as social media posts or customer reviews. The goal of this analysis is to understand the overall sentiment of a particular topic or product, as well as any trends or patterns in the sentiment over time.\n",
    "\n",
    "To perform this analysis, you would first need to gather a large collection of text data that is relevant to the topic or product you are interested in. This could be done using web scraping or by using an API to access social media data. Next, you would use the VADER tool or a similar method to calculate the sentiment scores for each piece of text. These scores could then be aggregated and analyzed to understand the overall sentiment of the data, as well as any trends or patterns in the sentiment over time.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "195d7958",
   "metadata": {},
   "source": [
    "\n",
    "Predicting the sentiment of a piece of text based on its features:\n",
    "\n",
    "The second technique involves using machine learning to build a model that can predict the sentiment of a piece of text based on its features. The goal of this model is to classify text data into positive, negative, or neutral sentiment categories.\n",
    "\n",
    "To build such a model, you would need to first gather a large collection of text data that has been labeled with its sentiment (e.g., positive, negative, or neutral). This labeled text data would be used to train the machine learning model to predict the sentiment of new, unseen text data.\n",
    "\n",
    "Next, you would extract features from the text data that are relevant for predicting its sentiment. These features could include the words and phrases contained in the text, as well as other information such as capitalization, punctuation, and the context in which the words and phrases are used.\n",
    "\n",
    "Once you have extracted the features from the text data, you would use them to train a machine learning model, such as a support vector machine or a decision tree, to predict the sentiment of new text data. To do this, you would split the labeled text data into a training set and a test set, and use the training set to fit the machine learning model. You could then evaluate the performance of the model on the test set to see how well it can predict the sentiment of unseen text data.\n",
    "\n",
    "If the model performs well on the test set, you could then use it to classify new, unseen text data into positive, negative, or neutral sentiment categories. This could be useful for a variety of applications, such as automatically classifying customer reviews or social media posts as positive, negative, or neutral."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d49e9c3",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Hutto, C.J. and Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for Sentiment Analysis of Social Media Text. Eighth International Conference on Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014.\n",
    "\n",
    "Hutto, C.J. and Gilbert, E.E. (2017). Examining the Utility of the VADER Sentiment Lexicon for Social Science Research. Behavior Research Methods, 49(1), pp.261-271.\n",
    "\n",
    "Mullen, T., Loper, E. and Hovy, E. (2018). Sentiment Analysis of Social Media Texts: A Systematic Review of Approaches and Tools. Information Processing & Management, 54(4), pp.588-606.\n",
    "\n",
    "Sobhani, F. and Raza, S. (2019). Sentiment Analysis of Social Media Posts: A Survey of Techniques and Tools. ACM Computing Surveys, 52(2), pp.1-34.\n",
    "\n",
    "These references cover the development and use of the VADER tool for sentiment analysis, as well as a review of different approaches and tools for sentiment analysis of social media text. The first reference is a conference paper that describes the design and evaluation of the VADER tool, while the second reference is a journal article that discusses the utility of the VADER lexicon for social science research. The third and fourth references are survey articles that provide an overview of techniques and tools for sentiment analysis of social media posts."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0 (main, Oct 24 2022, 18:26:48) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "5238573367df39f7286bb46f9ff5f08f63a01a80960060ce41e3c79b190280fa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
